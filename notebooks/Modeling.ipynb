{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import logging\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import  LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.callbacks import DeadlineStopper, VerboseCallback, DeltaXStopper\n",
    "\n",
    "import nltk\n",
    "import nltk.corpus \n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_news = pd.read_csv('../data/processed/train.csv')\n",
    "val_news = pd.read_csv('../data/processed/val.csv')\n",
    "test_news = pd.read_csv('../data/processed/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the first time in history, the share of the national popular vote margin is smaller than the Latino vote margin.\n",
      "Since 2000, nearly 12 million Americans have slipped out of the middle class and into poverty.\n",
      "When Mitt Romney was governor of Massachusetts, we didnt just slow the rate of growth of our government, we actually cut it.\n",
      "The economy bled $24 billion due to the government shutdown.\n",
      "Most of the (Affordable Care Act) has already in some sense been waived or otherwise suspended.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10,15):\n",
    "    print(train_news['statement'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False News\n",
    "\n",
    "1. Says the Annies List political group supports third-trimester abortions on demand.\n",
    "2. Health care reform legislation is likely to mandate free sex change surgeries.\n",
    "3. Jim Dunnam has not lived in the district he represents for years now.\n",
    "4. When Mitt Romney was governor of Massachusetts, we didnt just slow the rate of growth of our government, we actually cut it.\n",
    "5. Most of the (Affordable Care Act) has already in some sense been waived or otherwise suspended.\n",
    "\n",
    "\n",
    "True News\n",
    "1. When did the decline of coal start? It started when natural gas took off that started to begin in (President George W.) Bushs administration.\n",
    "2. Hillary Clinton agrees with John McCain \"by voting to give George Bush the benefit of the doubt on Iran.\"\n",
    "3. The economic turnaround started at the end of my term.\n",
    "4. The Chicago Bears have had more starting quarterbacks in the last 10 years than the total number of tenured (UW) faculty fired during the last two decades.\n",
    "5. I'm the only person on this stage who has worked actively just last year passing, along with Russ Feingold, some of the toughest ethics reform since Watergate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>True</td>\n",
       "      <td>The Chicago Bears have had more starting quart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>Jim Dunnam has not lived in the district he re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>I'm the only person on this stage who has work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>True</td>\n",
       "      <td>However, it took $19.5 million in Oregon Lotte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>Says GOP primary opponents Glenn Grothman and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>True</td>\n",
       "      <td>For the first time in history, the share of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>True</td>\n",
       "      <td>Since 2000, nearly 12 million Americans have s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>False</td>\n",
       "      <td>When Mitt Romney was governor of Massachusetts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>True</td>\n",
       "      <td>The economy bled $24 billion due to the govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>False</td>\n",
       "      <td>Most of the (Affordable Care Act) has already ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label                                          statement\n",
       "0   False  Says the Annies List political group supports ...\n",
       "1    True  When did the decline of coal start? It started...\n",
       "2    True  Hillary Clinton agrees with John McCain \"by vo...\n",
       "3   False  Health care reform legislation is likely to ma...\n",
       "4    True  The economic turnaround started at the end of ...\n",
       "5    True  The Chicago Bears have had more starting quart...\n",
       "6   False  Jim Dunnam has not lived in the district he re...\n",
       "7    True  I'm the only person on this stage who has work...\n",
       "8    True  However, it took $19.5 million in Oregon Lotte...\n",
       "9    True  Says GOP primary opponents Glenn Grothman and ...\n",
       "10   True  For the first time in history, the share of th...\n",
       "11   True  Since 2000, nearly 12 million Americans have s...\n",
       "12  False  When Mitt Romney was governor of Massachusetts...\n",
       "13   True  The economy bled $24 billion due to the govern...\n",
       "14  False  Most of the (Affordable Care Act) has already ..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_news.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10235</th>\n",
       "      <td>True</td>\n",
       "      <td>There are a larger number of shark attacks in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>True</td>\n",
       "      <td>Democrats have now become the party of the [At...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10237</th>\n",
       "      <td>True</td>\n",
       "      <td>Says an alternative to Social Security that op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10238</th>\n",
       "      <td>False</td>\n",
       "      <td>On lifting the U.S. Cuban embargo and allowing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10239</th>\n",
       "      <td>False</td>\n",
       "      <td>The Department of Veterans Affairs has a manua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10240 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                          statement\n",
       "0      False  Says the Annies List political group supports ...\n",
       "1       True  When did the decline of coal start? It started...\n",
       "2       True  Hillary Clinton agrees with John McCain \"by vo...\n",
       "3      False  Health care reform legislation is likely to ma...\n",
       "4       True  The economic turnaround started at the end of ...\n",
       "...      ...                                                ...\n",
       "10235   True  There are a larger number of shark attacks in ...\n",
       "10236   True  Democrats have now become the party of the [At...\n",
       "10237   True  Says an alternative to Social Security that op...\n",
       "10238  False  On lifting the U.S. Cuban embargo and allowing...\n",
       "10239  False  The Department of Veterans Affairs has a manua...\n",
       "\n",
       "[10240 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>True</td>\n",
       "      <td>Says his budget provides the highest state fun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>False</td>\n",
       "      <td>Ive been here almost every day.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>False</td>\n",
       "      <td>In the early 1980s, Sen. Edward Kennedy secret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>False</td>\n",
       "      <td>Says an EPA permit languished under Strickland...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>False</td>\n",
       "      <td>Says the governor is going around the state ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1267 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                          statement\n",
       "0      True  Building a wall on the U.S.-Mexico border will...\n",
       "1     False  Wisconsin is on pace to double the number of l...\n",
       "2     False  Says John McCain has done nothing to help the ...\n",
       "3      True  Suzanne Bonamici supports a plan that will cut...\n",
       "4     False  When asked by a reporter whether hes at the ce...\n",
       "...     ...                                                ...\n",
       "1262   True  Says his budget provides the highest state fun...\n",
       "1263  False                    Ive been here almost every day.\n",
       "1264  False  In the early 1980s, Sen. Edward Kennedy secret...\n",
       "1265  False  Says an EPA permit languished under Strickland...\n",
       "1266  False  Says the governor is going around the state ta...\n",
       "\n",
       "[1267 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>We have less Americans working now than in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>When Obama was sworn into office, he DID NOT u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>Says Having organizations parading as being so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>Says nearly half of Oregons children are poor.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>On attacks by Republicans that various program...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>True</td>\n",
       "      <td>For the first time in more than a decade, impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>True</td>\n",
       "      <td>Says Donald Trump has bankrupted his companies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>True</td>\n",
       "      <td>John McCain and George Bush have \"absolutely n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>False</td>\n",
       "      <td>A new poll shows 62 percent support the presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>False</td>\n",
       "      <td>No one claims the report vindicating New Jerse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1284 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                          statement\n",
       "0     False  We have less Americans working now than in the...\n",
       "1     False  When Obama was sworn into office, he DID NOT u...\n",
       "2     False  Says Having organizations parading as being so...\n",
       "3      True     Says nearly half of Oregons children are poor.\n",
       "4      True  On attacks by Republicans that various program...\n",
       "...     ...                                                ...\n",
       "1279   True  For the first time in more than a decade, impo...\n",
       "1280   True  Says Donald Trump has bankrupted his companies...\n",
       "1281   True  John McCain and George Bush have \"absolutely n...\n",
       "1282  False  A new poll shows 62 percent support the presid...\n",
       "1283  False  No one claims the report vindicating New Jerse...\n",
       "\n",
       "[1284 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(train_news), display(test_news), display(val_news)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging train & val data for K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the training and validation data together, so that I can peroform k-fold cross validation \n",
    "#and shuffle the data to reduce the bias\n",
    "labelEncoder = LabelEncoder()\n",
    "frames = [train_news, val_news]\n",
    "train_val = pd.concat(frames)\n",
    "train_val['label'].value_counts()\n",
    "train_val['label'] = labelEncoder.fit_transform(train_val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>1</td>\n",
       "      <td>For the first time in more than a decade, impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>1</td>\n",
       "      <td>Says Donald Trump has bankrupted his companies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>1</td>\n",
       "      <td>John McCain and George Bush have \"absolutely n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1282</th>\n",
       "      <td>0</td>\n",
       "      <td>A new poll shows 62 percent support the presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>0</td>\n",
       "      <td>No one claims the report vindicating New Jerse...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11524 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                          statement\n",
       "0         0  Says the Annies List political group supports ...\n",
       "1         1  When did the decline of coal start? It started...\n",
       "2         1  Hillary Clinton agrees with John McCain \"by vo...\n",
       "3         0  Health care reform legislation is likely to ma...\n",
       "4         1  The economic turnaround started at the end of ...\n",
       "...     ...                                                ...\n",
       "1279      1  For the first time in more than a decade, impo...\n",
       "1280      1  Says Donald Trump has bankrupted his companies...\n",
       "1281      1  John McCain and George Bush have \"absolutely n...\n",
       "1282      0  A new poll shows 62 percent support the presid...\n",
       "1283      0  No one claims the report vindicating New Jerse...\n",
       "\n",
       "[11524 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    '''\n",
    "    What will be covered:\n",
    "    1. Remove punctuation\n",
    "    2. Remove stopwords\n",
    "    3. Return list of clean text words\n",
    "    '''\n",
    "    \n",
    "    #1\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    #2\n",
    "    clean_words = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]\n",
    "    \n",
    "    #3\n",
    "    return clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_vect = CountVectorizer(analyzer=process_text)\n",
    "# tfidf_transformer = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Weighting\n",
    "\n",
    "Not all words are equally important to a particular document / category. For example, while words like ‘murder’, ‘knife’ and ‘abduction’ are important to a crime related document, words like ‘news’ and ‘reporter’ may not be quite as important. \n",
    "\n",
    "### Binary Weighting\n",
    "The most basic form of feature weighting, is binary weighting. Where if a word is present in a document, the weight is ‘1’ and if the word is absent the weight is ‘0’. \n",
    "\n",
    "### CountVectorizer\n",
    "\n",
    "It Convert a collection of text documents to a matrix of token counts.\n",
    "\n",
    "\n",
    "### Tfidf Weighting \n",
    "\n",
    "TF-IDF weighting where words that are unique to a particular document would have higher weights compared to words that are used commonly across documents. \n",
    "\n",
    "1. TF (Term Frequency): The number of times a word appears in a document divded by the total number of words in the document. Every document has its own term frequency.\n",
    "\n",
    "2. IDF (Inverse Data Frequency): The log of the number of documents divided by the number of documents that contain the word w. Inverse data frequency determines the weight of rare words across all documents in the corpus.\n",
    "\n",
    "3. Lastly, the TF-IDF is simply the TF multiplied by IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def extract_features(field,training_data,testing_data,type):\n",
    "    \"\"\"Extract features using different methods\"\"\"\n",
    "    \n",
    "    logging.info(\"Extracting features and creating vocabulary...\")\n",
    "    \n",
    "    if \"binary\" in type:\n",
    "        \n",
    "        # BINARY FEATURE REPRESENTATION\n",
    "        cv= CountVectorizer(binary=True, max_df=0.95, analyzer=process_text)\n",
    "        cv.fit_transform(training_data.values)\n",
    "        \n",
    "        train_feature_set=cv.transform(training_data.values)\n",
    "        test_feature_set=cv.transform(testing_data.values)\n",
    "        \n",
    "        return train_feature_set,test_feature_set,cv\n",
    "  \n",
    "    elif \"counts\" in type:\n",
    "        \n",
    "        # COUNT BASED FEATURE REPRESENTATION\n",
    "        cv= CountVectorizer(binary=False, max_df=0.95, analyzer=process_text)\n",
    "        cv.fit_transform(training_data.values)\n",
    "        \n",
    "        train_feature_set=cv.transform(training_data.values)\n",
    "        test_feature_set=cv.transform(testing_data.values)\n",
    "        \n",
    "        return train_feature_set,test_feature_set,cv\n",
    "    \n",
    "    else:    \n",
    "        \n",
    "        # TF-IDF BASED FEATURE REPRESENTATION\n",
    "        tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_df=0.95, analyzer=process_text)\n",
    "        tfidf_vectorizer.fit_transform(training_data.values)\n",
    "        \n",
    "        train_feature_set=tfidf_vectorizer.transform(training_data.values)\n",
    "        test_feature_set=tfidf_vectorizer.transform(testing_data.values)\n",
    "        \n",
    "        return train_feature_set,test_feature_set,tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, train_val, field=\"statement\",feature_rep=\"binary\"):\n",
    "    \"\"\"\n",
    "    Training the classifier for the provided features.\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(\"Starting model training...\")\n",
    "    \n",
    "    scores = []\n",
    "    confusion = np.array([[0,0],[0,0]])\n",
    "    \n",
    "    # GET A TRAIN TEST SPLIT (set seed for consistent results)\n",
    "    training_data, testing_data = train_test_split(train_val,random_state = 2000,)\n",
    "\n",
    "    # features\n",
    "    X_train=training_data['statement']\n",
    "    X_test=testing_data['statement']\n",
    "    \n",
    "    # GET LABELS\n",
    "    Y_train=training_data['label'].values\n",
    "    Y_test=testing_data['label'].values\n",
    "     \n",
    "    # GET FEATURES\n",
    "    train_features,test_features,feature_transformer=extract_features(field,X_train,X_test,type=feature_rep)\n",
    "\n",
    "    # INIT LOGISTIC REGRESSION CLASSIFIER\n",
    "    logging.info(\"Training a Classification Model...\")\n",
    "#     scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "    model=classifier.fit(train_features,Y_train)\n",
    "\n",
    "    # GET PREDICTIONS\n",
    "    predictions = model.predict(test_features)\n",
    "    \n",
    "    # GET EVALUATION NUMBERS ON TEST SET -- HOW DID WE DO?\n",
    "    logging.info(\"Starting evaluation...\")\n",
    "    score = f1_score(Y_test,predictions)\n",
    "    print(classification_report(Y_test,predictions))\n",
    "    print(confusion_matrix(Y_test,predictions))\n",
    "    logging.info(\"Done training and evaluation.\")\n",
    "    \n",
    "    return model,feature_transformer,score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric\n",
    "\n",
    "I need to minimize false positives (number of fake news predicted as real news) as it can be very misleadling . For class 0 i.e. 'fake', recall should be high as well as precision. Because we want our model to perform well on both classes (real & fake). In short, we need to maximize f1-score.\n",
    "\n",
    "### Cases I considered to choose the right metric\n",
    "\n",
    "**1. Maximizing recall of class 0 (fake) or minimizing false positives(FP)?**\n",
    "Well, in extreme case, what if all the news predicted by model are labelled as 'fake'. Recall will still be 1, but overall model is really bad i.e. not able to predict class 1 ('real'). \n",
    "\n",
    "Ex=> TN = 553, FP = 0, TP = 0, FN = 714\n",
    "\n",
    "Class0-Recall = TN / (TN + FP) = 1\n",
    "Class0-Precision = TN / (TN + FN) = 0.43\n",
    "\n",
    "F1-Score = 2 * Class0-Recall * Class0-Precision/(Class0-Recall + Class0-Precision) = 0.60\n",
    "\n",
    "Recall, Precision and F1-score for class 1 will be 0.\n",
    "\n",
    "**2. Considering an extreme case, if all the news classified as True (Even, fake news are predicted as True).**\n",
    "\n",
    "Ex=>  TN = 0, FP = 553, TP = 714, FN =0\n",
    "In that case, TN will be 0, which led to Precision 0, Recall 0 and F1 = 0 for class 0 ('fake').\n",
    "\n",
    "For class 1, Class1-Recall = TP / (TP + FN) = 1\n",
    "Class1-Precision = TP / (TP + FP) = 0.56"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Algorithms\n",
    "\n",
    "1. Naive Bayes (NB)\n",
    "2. Logistics Regression\n",
    "3. SVM\n",
    "4. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Well, when assumption of independence holds, a Naive Bayes classifier performs better compare to other models like logistic regression and you need less training data. An advantage of naive Bayes is that it only requires a small number of training data to estimate the parameters necessary for classification. \n",
    "\n",
    "Bayes’ Theorem provides a way that we can calculate the probability of a piece of data belonging to a given class, given our prior knowledge. Bayes’ Theorem is stated as:\n",
    "\n",
    "P(class|data) = (P(data|class) * P(class)) / P(data)\n",
    "\n",
    "Where P(class|data) is the probability of class given the provided data.\n",
    "\n",
    "Naive Bayes is a classification algorithm for binary (two-class) and multiclass classification problems. It is called Naive Bayes or idiot Bayes because the calculations of the probabilities for each class are simplified to make their calculations tractable.\n",
    "\n",
    "Rather than attempting to calculate the probabilities of each attribute value, they are assumed to be conditionally independent given the class value.\n",
    "\n",
    "This is a very strong assumption that is most unlikely in real data, i.e. that the attributes do not interact. Nevertheless, the approach performs surprisingly well on data where this assumption does not hold.\n",
    "\n",
    "### Multinomial NB\n",
    "\n",
    "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models with Different Types of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-24 12:44:31,863 : INFO : Starting model training...\n",
      "2020-11-24 12:44:31,875 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - binary features with statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-24 12:45:21,018 : INFO : Training a Classification Model...\n",
      "2020-11-24 12:45:21,030 : INFO : Starting evaluation...\n",
      "2020-11-24 12:45:21,044 : INFO : Done training and evaluation.\n",
      "2020-11-24 12:45:21,045 : INFO : Starting model training...\n",
      "2020-11-24 12:45:21,049 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.47      0.52      1273\n",
      "           1       0.64      0.73      0.68      1608\n",
      "\n",
      "    accuracy                           0.62      2881\n",
      "   macro avg       0.61      0.60      0.60      2881\n",
      "weighted avg       0.61      0.62      0.61      2881\n",
      "\n",
      "[[ 602  671]\n",
      " [ 431 1177]]\n",
      "Model - counts features with statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-24 12:46:10,672 : INFO : Training a Classification Model...\n",
      "2020-11-24 12:46:10,677 : INFO : Starting evaluation...\n",
      "2020-11-24 12:46:10,694 : INFO : Done training and evaluation.\n",
      "2020-11-24 12:46:10,697 : INFO : Starting model training...\n",
      "2020-11-24 12:46:10,700 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.48      0.53      1273\n",
      "           1       0.64      0.73      0.68      1608\n",
      "\n",
      "    accuracy                           0.62      2881\n",
      "   macro avg       0.61      0.61      0.60      2881\n",
      "weighted avg       0.62      0.62      0.61      2881\n",
      "\n",
      "[[ 610  663]\n",
      " [ 431 1177]]\n",
      "Model - tfidf features with statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-24 12:46:59,924 : INFO : Training a Classification Model...\n",
      "2020-11-24 12:46:59,927 : INFO : Starting evaluation...\n",
      "2020-11-24 12:46:59,938 : INFO : Done training and evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.29      0.39      1273\n",
      "           1       0.60      0.86      0.71      1608\n",
      "\n",
      "    accuracy                           0.61      2881\n",
      "   macro avg       0.61      0.57      0.55      2881\n",
      "weighted avg       0.61      0.61      0.57      2881\n",
      "\n",
      "[[ 367  906]\n",
      " [ 227 1381]]\n"
     ]
    }
   ],
   "source": [
    "# model,transformer,score,confusion,report=train_model(nb_clf, train_val,field=field,feature_rep=feature_rep)\n",
    "# print(\"\\nF1-score={0}; confusion={1}; classification_report={2}\".format(score,confusion,report))\n",
    "field='statement'\n",
    "feature_reps=['binary','counts','tfidf']\n",
    "nb_results=[]\n",
    "nb_clf = MultinomialNB()\n",
    "for feature_rep in feature_reps:\n",
    "        print(f'Model - {feature_rep} features with statement')\n",
    "        nb_model,transformer,score=train_model(nb_clf,train_val,field=field,feature_rep=feature_rep)\n",
    "        nb_results.append([field,feature_rep,score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Results of Various Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_fields</th>\n",
       "      <th>feature_representation</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>statement</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.709114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>statement</td>\n",
       "      <td>counts</td>\n",
       "      <td>0.682715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>statement</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.681134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_fields feature_representation  f1-score\n",
       "2   statement                  tfidf  0.709114\n",
       "1   statement                 counts  0.682715\n",
       "0   statement                 binary  0.681134"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_df_results=pd.DataFrame(nb_results,columns=['text_fields','feature_representation','f1-score'])\n",
    "nb_df_results.sort_values(by=['f1-score'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# nb_clf_pipeline = Pipeline([('vect', count_vect),\n",
    "#                       ('tfidf', tfidf_transformer),\n",
    "#                       ('nb_clf', MultinomialNB()),\n",
    "#  ])\n",
    "# nb_clf_pipeline.fit(train_news['statement'], train_label)\n",
    "# predicted = nb_clf_pipeline.predict(test_news['statement'])\n",
    "# print(np.mean(predicted == test_label))\n",
    "# print(classification_report(test_label,predicted))\n",
    "# print(confusion_matrix(test_label,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logistic regression\n",
    "\n",
    "The underlying algorithm is also fairly easy to understand. More importantly, in the NLP world, it’s generally accepted that Logistic Regression is a great starter algorithm for text related classification (https://web.stanford.edu/~jurafsky/slp3/5.pdf). \n",
    "\n",
    "**How hypothesis makes prediction in logistics regression?**\n",
    "\n",
    "This algorithm uses sigmoid function(g(z)). If we want to predict y=1 or y=0.\n",
    "If estimated probability of y=1 is h(x)>=0.5 then the ouput is more likely to be \"y=1\" \n",
    "but if  h(x) < 0.5, the output is more likely to be is \"y=0\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models with Different Types of Features¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 13:04:05,625 : INFO : Starting model training...\n",
      "2020-11-23 13:04:05,643 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - binary features with statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 13:04:52,819 : INFO : Training a Classification Model...\n",
      "2020-11-23 13:04:52,942 : INFO : Starting evaluation...\n",
      "2020-11-23 13:04:52,958 : INFO : Done training and evaluation.\n",
      "2020-11-23 13:04:52,960 : INFO : Starting model training...\n",
      "2020-11-23 13:04:52,965 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.51      0.52      1273\n",
      "           1       0.63      0.66      0.64      1608\n",
      "\n",
      "    accuracy                           0.59      2881\n",
      "   macro avg       0.58      0.58      0.58      2881\n",
      "weighted avg       0.59      0.59      0.59      2881\n",
      "\n",
      "[[ 645  628]\n",
      " [ 550 1058]]\n",
      "Model - counts features with statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 13:05:33,156 : INFO : Training a Classification Model...\n",
      "2020-11-23 13:05:33,246 : INFO : Starting evaluation...\n",
      "2020-11-23 13:05:33,259 : INFO : Done training and evaluation.\n",
      "2020-11-23 13:05:33,262 : INFO : Starting model training...\n",
      "2020-11-23 13:05:33,267 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.50      0.52      1273\n",
      "           1       0.62      0.65      0.64      1608\n",
      "\n",
      "    accuracy                           0.59      2881\n",
      "   macro avg       0.58      0.58      0.58      2881\n",
      "weighted avg       0.58      0.59      0.58      2881\n",
      "\n",
      "[[ 635  638]\n",
      " [ 556 1052]]\n",
      "Model - tfidf features with statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 13:06:12,431 : INFO : Training a Classification Model...\n",
      "2020-11-23 13:06:12,474 : INFO : Starting evaluation...\n",
      "2020-11-23 13:06:12,490 : INFO : Done training and evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.49      0.52      1273\n",
      "           1       0.63      0.69      0.66      1608\n",
      "\n",
      "    accuracy                           0.60      2881\n",
      "   macro avg       0.59      0.59      0.59      2881\n",
      "weighted avg       0.60      0.60      0.60      2881\n",
      "\n",
      "[[ 625  648]\n",
      " [ 496 1112]]\n"
     ]
    }
   ],
   "source": [
    "field='statement'\n",
    "feature_reps=['binary','counts','tfidf']\n",
    "lr_results=[]\n",
    "LogR_clf = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "\n",
    "for feature_rep in feature_reps:\n",
    "        print(f'Model - {feature_rep} features with statement')\n",
    "        lr_model,transformer,score=train_model(LogR_clf,train_val,field=field,feature_rep=feature_rep)\n",
    "        lr_results.append([field,feature_rep,score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistics Regression Results of Various Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_fields</th>\n",
       "      <th>feature_representation</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>statement</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.660333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>statement</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.642380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>statement</td>\n",
       "      <td>counts</td>\n",
       "      <td>0.637962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_fields feature_representation  f1-score\n",
       "2   statement                  tfidf  0.660333\n",
       "0   statement                 binary  0.642380\n",
       "1   statement                 counts  0.637962"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_df_results=pd.DataFrame(lr_results,columns=['text_fields','feature_representation','f1-score'])\n",
    "lr_df_results.sort_values(by=['f1-score'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you see how the performance of logistics model is improved using tfidf over counts and binary weightning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "Support vector machines is an algorithm that determines the best decision boundary between vectors that belong to a given group (or category) and vectors that do not belong to it. That’s it. It can be applied to any kind of vectors which encode any kind of data. This means that in order to leverage the power of svm text classification, texts have to be transformed into vectors.\n",
    "\n",
    "So, when SVM determines the decision boundary we mentioned above, SVM decides where to draw the best “line” (or the best hyperplane) that divides the space into two subspaces: one for the vectors which belong to the given category and one for the vectors which do not belong to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models with Different Types of Features¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 13:06:12,526 : INFO : Starting model training...\n",
      "2020-11-23 13:06:12,535 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Model - binary features with statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 13:06:52,164 : INFO : Training a Classification Model...\n",
      "2020-11-23 13:06:52,314 : INFO : Starting evaluation...\n",
      "2020-11-23 13:06:52,325 : INFO : Done training and evaluation.\n",
      "2020-11-23 13:06:52,327 : INFO : Starting model training...\n",
      "2020-11-23 13:06:52,332 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.51      0.52      1273\n",
      "           1       0.62      0.64      0.63      1608\n",
      "\n",
      "    accuracy                           0.59      2881\n",
      "   macro avg       0.58      0.58      0.58      2881\n",
      "weighted avg       0.58      0.59      0.58      2881\n",
      "\n",
      "[[ 650  623]\n",
      " [ 572 1036]]\n",
      "SVM Model - counts features with statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 13:07:32,189 : INFO : Training a Classification Model...\n",
      "2020-11-23 13:07:32,416 : INFO : Starting evaluation...\n",
      "2020-11-23 13:07:32,426 : INFO : Done training and evaluation.\n",
      "2020-11-23 13:07:32,428 : INFO : Starting model training...\n",
      "2020-11-23 13:07:32,432 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.51      0.51      1273\n",
      "           1       0.62      0.63      0.62      1608\n",
      "\n",
      "    accuracy                           0.58      2881\n",
      "   macro avg       0.57      0.57      0.57      2881\n",
      "weighted avg       0.57      0.58      0.58      2881\n",
      "\n",
      "[[ 644  629]\n",
      " [ 593 1015]]\n",
      "SVM Model - tfidf features with statement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 13:08:19,113 : INFO : Training a Classification Model...\n",
      "2020-11-23 13:08:19,145 : INFO : Starting evaluation...\n",
      "2020-11-23 13:08:19,154 : INFO : Done training and evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.49      0.52      1273\n",
      "           1       0.63      0.69      0.66      1608\n",
      "\n",
      "    accuracy                           0.60      2881\n",
      "   macro avg       0.59      0.59      0.59      2881\n",
      "weighted avg       0.60      0.60      0.60      2881\n",
      "\n",
      "[[ 626  647]\n",
      " [ 506 1102]]\n"
     ]
    }
   ],
   "source": [
    "field='statement'\n",
    "feature_reps=['binary','counts','tfidf']\n",
    "svm_results=[]\n",
    "svm_clf = svm.LinearSVC()\n",
    "\n",
    "for feature_rep in feature_reps:\n",
    "        print(f'SVM Model - {feature_rep} features with statement')\n",
    "        svm_model,transformer,score=train_model(svm_clf,train_val,field=field,feature_rep=feature_rep)\n",
    "        svm_results.append([field,feature_rep,score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Results of Various Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_fields</th>\n",
       "      <th>feature_representation</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>statement</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.656539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>statement</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.634221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>statement</td>\n",
       "      <td>counts</td>\n",
       "      <td>0.624231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_fields feature_representation  f1-score\n",
       "2   statement                  tfidf  0.656539\n",
       "0   statement                 binary  0.634221\n",
       "1   statement                 counts  0.624231"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_df_results=pd.DataFrame(svm_results,columns=['text_fields','feature_representation','f1-score'])\n",
    "svm_df_results.sort_values(by=['f1-score'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Given the nature of random forests (a bagging decision tree), it is true that you may come up with a rather weak classifier, especially if only a couple of features are truly significant to determine the outcome.\n",
    "\n",
    "However, keep in mind that in the case of text classification, a preprocessing phase is required to get either your TF or TF-IDF matrix, through which you have already made a selection of pertinent features. Potentially, all features are relevant in this matrix, so the random forest may be performant when you predict your outcome. (source: https://stats.stackexchange.com/questions/343954/random-forest-short-text-classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models with Different Types of Features¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 13:08:19,176 : INFO : Starting model training...\n",
      "2020-11-23 13:08:19,182 : INFO : Extracting features and creating vocabulary...\n",
      "2020-11-23 13:08:58,434 : INFO : Training a Classification Model...\n",
      "2020-11-23 13:10:13,064 : INFO : Starting evaluation...\n",
      "2020-11-23 13:10:13,074 : INFO : Done training and evaluation.\n",
      "2020-11-23 13:10:13,121 : INFO : Starting model training...\n",
      "2020-11-23 13:10:13,124 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.43      0.50      1273\n",
      "           1       0.63      0.76      0.69      1608\n",
      "\n",
      "    accuracy                           0.61      2881\n",
      "   macro avg       0.61      0.60      0.59      2881\n",
      "weighted avg       0.61      0.61      0.60      2881\n",
      "\n",
      "[[ 547  726]\n",
      " [ 384 1224]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 13:10:56,751 : INFO : Training a Classification Model...\n",
      "2020-11-23 13:12:16,539 : INFO : Starting evaluation...\n",
      "2020-11-23 13:12:16,549 : INFO : Done training and evaluation.\n",
      "2020-11-23 13:12:16,551 : INFO : Starting model training...\n",
      "2020-11-23 13:12:16,555 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.44      0.50      1273\n",
      "           1       0.63      0.75      0.68      1608\n",
      "\n",
      "    accuracy                           0.61      2881\n",
      "   macro avg       0.60      0.59      0.59      2881\n",
      "weighted avg       0.61      0.61      0.60      2881\n",
      "\n",
      "[[ 560  713]\n",
      " [ 407 1201]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-23 13:13:03,172 : INFO : Training a Classification Model...\n",
      "2020-11-23 13:14:14,257 : INFO : Starting evaluation...\n",
      "2020-11-23 13:14:14,266 : INFO : Done training and evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.41      0.48      1273\n",
      "           1       0.62      0.76      0.68      1608\n",
      "\n",
      "    accuracy                           0.60      2881\n",
      "   macro avg       0.60      0.58      0.58      2881\n",
      "weighted avg       0.60      0.60      0.59      2881\n",
      "\n",
      "[[ 524  749]\n",
      " [ 392 1216]]\n"
     ]
    }
   ],
   "source": [
    "field='statement'\n",
    "feature_reps=['binary','counts','tfidf']\n",
    "rf_results=[]\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "for feature_rep in feature_reps:\n",
    "        rf_model,transformer,score=train_model(rf_clf,train_val,field=field,feature_rep=feature_rep)\n",
    "        rf_results.append([field,feature_rep,score])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Results of Various Models¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_fields</th>\n",
       "      <th>feature_representation</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>statement</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.688027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>statement</td>\n",
       "      <td>counts</td>\n",
       "      <td>0.681999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>statement</td>\n",
       "      <td>tfidf</td>\n",
       "      <td>0.680661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_fields feature_representation  f1-score\n",
       "0   statement                 binary  0.688027\n",
       "1   statement                 counts  0.681999\n",
       "2   statement                  tfidf  0.680661"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_df_results=pd.DataFrame(rf_results,columns=['text_fields','feature_representation','f1-score'])\n",
    "rf_df_results.sort_values(by=['f1-score'],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation\n",
    "\n",
    "With K-fold cross validation, you are testing how well your model is able to get trained by some data and then predict data it hasn't seen. We use cross validation for this because if you train using all the data you have, you have none left for testing. You could do this once, say by using 80% of the data to train and 20% to test, but what if the 20% you happened to pick to test happens to contain a bunch of points that are particularly easy (or particularly hard) to predict? We will not have come up with the best estimate possible of the models ability to learn and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#User defined functon for K-Fold cross validatoin\n",
    "def apply_kfold(classifier,train_val,field,feature_rep):\n",
    "    \"\"\"\n",
    "    K-fold cross validation on the the data\n",
    "    \"\"\"\n",
    "    k_fold = KFold(n_splits=5, shuffle=True)\n",
    "    scores = []\n",
    "    confusion = np.array([[0,0],[0,0]])\n",
    "\n",
    "    for fold_n, (train_index, valid_index) in enumerate(k_fold.split(train_val['statement'], train_val['label'])):\n",
    "        print(fold_n, len(train_index), len(valid_index))\n",
    "        train_x = train_val['statement'].iloc[train_index]\n",
    "        train_y = train_val['label'].iloc[train_index]\n",
    "    \n",
    "        valid_x = train_val['statement'].iloc[valid_index]\n",
    "        valid_y = train_val['label'].iloc[valid_index]\n",
    "        \n",
    "        # GET FEATURES\n",
    "        train_features,val_features,feature_transformer=extract_features(field,train_x,valid_x,type=feature_rep)\n",
    "        \n",
    "        # INIT CLASSIFIER\n",
    "        logging.info(\"Training a Classification Model...\")\n",
    "        classifier.fit(train_features, train_y)\n",
    "        predictions = classifier.predict(val_features)\n",
    "        \n",
    "        confusion += confusion_matrix(valid_y,predictions)\n",
    "        score = f1_score(valid_y,predictions)\n",
    "        scores.append(score)\n",
    "        \n",
    "    return (print('Total statements classified:', len(train_val['statement'])),\n",
    "    print('Score:', sum(scores)/len(scores)),\n",
    "    print('score length', len(scores)),\n",
    "    print('Confusion matrix:'),\n",
    "    print(confusion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-24 13:53:46,582 : INFO : Extracting features and creating vocabulary...\n",
      "/opt/anaconda3/envs/newenv/lib/python3.8/site-packages/sklearn/model_selection/_split.py:292: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d5cd9a8a7452>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0msearch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBayesSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_spaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# perform the search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m# report the best result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/newenv/lib/python3.8/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, callback)\u001b[0m\n\u001b[1;32m    690\u001b[0m                 \u001b[0mn_points_adjusted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m                 optim_result = self._step(\n\u001b[0m\u001b[1;32m    693\u001b[0m                     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m                     \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_points_adjusted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/newenv/lib/python3.8/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, X, y, search_space, optimizer, groups, n_points)\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    580\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrefit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/newenv/lib/python3.8/site-packages/skopt/searchcv.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, groups, parameter_iterable)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0mcv_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         out = Parallel(\n\u001b[0m\u001b[1;32m    411\u001b[0m             \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/newenv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/newenv/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/newenv/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    538\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    539\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/newenv/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/newenv/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "field='statement'\n",
    "feature_reps=['binary','counts','tfidf']\n",
    "# GET FEATURES\n",
    "train_features,feature_transformer=extract_final_features('statement',train_val['statement'],type='binary')\n",
    "    \n",
    "# define search space\n",
    "params = dict()\n",
    "params['C'] = (1e-6, 100.0, 'log-uniform')\n",
    "params['gamma'] = (1e-6, 100.0, 'log-uniform')\n",
    "params['degree'] = (1,5)\n",
    "params['kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "# define evaluation\n",
    "cv = StratifiedKFold(n_splits=5, random_state=1)\n",
    "# define the search\n",
    "search = BayesSearchCV(estimator=SVC(), search_spaces=params, n_jobs=-1, cv=cv)\n",
    "# perform the search\n",
    "search.fit(train_features, train_val['label'])\n",
    "# report the best result\n",
    "print(search.best_score_)\n",
    "print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define search space for Logistics Regresssion\n",
    "\n",
    "params = dict()\n",
    "params['C'] = (1e-6, 100.0, 'log-uniform')\n",
    "params['gamma'] = (1e-6, 100.0, 'log-uniform')\n",
    "params['degree'] = (1,5)\n",
    "params['kernel'] = ['linear', 'poly', 'rbf', 'sigmoid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes with K-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:49,036 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - binary features with statement\n",
      "0 10232 2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:49,838 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:49,858 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:50,866 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:50,886 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:51,376 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:51,386 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:51,782 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:51,791 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:52,145 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:52,158 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 12791\n",
      "Score: 0.6743321808352938\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2731 2926]\n",
      " [2016 5118]]\n",
      "Model - counts features with statement\n",
      "0 10232 2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:52,506 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:52,517 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:52,872 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:52,882 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:53,232 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:53,242 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:53,787 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:53,797 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:54,139 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:54,153 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 12791\n",
      "Score: 0.6666163925388202\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2766 2891]\n",
      " [2122 5012]]\n",
      "Model - tfidf features with statement\n",
      "0 10232 2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:54,507 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:54,516 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:54,867 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:54,878 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:55,233 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:55,242 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:55,591 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:45:55,599 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:45:55,944 : INFO : Training a Classification Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 12791\n",
      "Score: 0.7094457956840234\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[1537 4120]\n",
      " [ 947 6187]]\n"
     ]
    }
   ],
   "source": [
    "field='statement'\n",
    "feature_reps=['binary','counts','tfidf']\n",
    "nb_results=[]\n",
    "nb_clf = MultinomialNB()\n",
    "for feature_rep in feature_reps:\n",
    "        print(f'Model - {feature_rep} features with statement')\n",
    "        apply_kfold(nb_clf,train_val,field=field,feature_rep=feature_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistics Regression with K-fold cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:07,313 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - binary features with statement\n",
      "0 10232 2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:07,699 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:47:07,869 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]1 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:08,382 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:47:08,539 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]2 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:08,938 : INFO : Training a Classification Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:09,169 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:09,569 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:47:09,735 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]4 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:10,103 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:47:10,278 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Total statements classified: 12791\n",
      "Score: 0.6300608298258705\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2927 2730]\n",
      " [2595 4539]]\n",
      "Model - counts features with statement\n",
      "0 10232 2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:10,657 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:47:10,824 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]1 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:11,212 : INFO : Training a Classification Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:11,499 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:12,023 : INFO : Training a Classification Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:12,241 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:12,707 : INFO : Training a Classification Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:13,062 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:13,467 : INFO : Training a Classification Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:13,682 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 12791\n",
      "Score: 0.6337859530999068\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2861 2796]\n",
      " [2526 4608]]\n",
      "Model - tfidf features with statement\n",
      "0 10232 2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:14,133 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:47:14,207 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]1 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:14,587 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:47:14,658 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]2 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:15,092 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:47:15,158 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]3 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:15,582 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:47:15,650 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]4 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:16,063 : INFO : Training a Classification Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Total statements classified: 12791\n",
      "Score: 0.6639971147599301\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2799 2858]\n",
      " [2168 4966]]\n"
     ]
    }
   ],
   "source": [
    "field='statement'\n",
    "feature_reps=['binary','counts','tfidf']\n",
    "LogR_clf = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "\n",
    "for feature_rep in feature_reps:\n",
    "        print(f'Model - {feature_rep} features with statement')\n",
    "        apply_kfold(LogR_clf,train_val,field=field,feature_rep=feature_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with K-fold cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:23,264 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - binary features with statement\n",
      "0 10232 2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:23,683 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:09:24,174 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:24,585 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:09:24,933 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:25,309 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:09:25,714 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:26,107 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:09:26,617 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:26,998 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:09:27,543 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 12791\n",
      "Score: 0.6227153624086335\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2920 2737]\n",
      " [2669 4465]]\n",
      "Model - counts features with statement\n",
      "0 10232 2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:27,939 : INFO : Training a Classification Model...\n",
      "/opt/anaconda3/envs/newenv/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "2020-11-20 16:09:28,851 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:29,226 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:09:30,151 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:30,566 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:09:31,317 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:31,693 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:09:32,605 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:32,994 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:09:33,858 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 12791\n",
      "Score: 0.6225832289724649\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2913 2744]\n",
      " [2669 4465]]\n",
      "Model - tfidf features with statement\n",
      "0 10232 2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:34,238 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:09:34,333 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:34,842 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:09:34,922 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:35,324 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:09:35,399 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:35,785 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:09:35,856 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:09:36,262 : INFO : Training a Classification Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 12791\n",
      "Score: 0.6525636545634905\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2841 2816]\n",
      " [2315 4819]]\n"
     ]
    }
   ],
   "source": [
    "field='statement'\n",
    "feature_reps=['binary','counts','tfidf']\n",
    "svm_clf = svm.LinearSVC()\n",
    "\n",
    "for feature_rep in feature_reps:\n",
    "        print(f'Model - {feature_rep} features with statement')\n",
    "        apply_kfold(svm_clf,train_val,field=field,feature_rep=feature_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF with K-fold cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:29,331 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model - binary features with statement\n",
      "0 10232 2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:47:29,724 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:48:59,125 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:48:59,563 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:50:30,532 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:50:30,997 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:52:02,014 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:52:02,461 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:53:35,295 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:53:35,669 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:55:06,945 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 12791\n",
      "Score: 0.7090001590443251\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2311 3346]\n",
      " [1378 5756]]\n",
      "Model - counts features with statement\n",
      "0 10232 2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:55:07,403 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:56:37,501 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:56:37,899 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:58:06,296 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:58:06,663 : INFO : Training a Classification Model...\n",
      "2020-11-20 15:59:36,646 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 15:59:37,061 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:01:06,434 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:01:06,872 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:02:34,596 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 12791\n",
      "Score: 0.7031539332144441\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2281 3376]\n",
      " [1435 5699]]\n",
      "Model - tfidf features with statement\n",
      "0 10232 2559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:02:34,959 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:03:55,720 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:03:56,082 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:05:17,504 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:05:17,895 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:06:38,275 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:06:38,671 : INFO : Training a Classification Model...\n",
      "2020-11-20 16:08:02,022 : INFO : Extracting features and creating vocabulary...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 10233 2558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:08:02,418 : INFO : Training a Classification Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total statements classified: 12791\n",
      "Score: 0.6990642799191381\n",
      "score length 5\n",
      "Confusion matrix:\n",
      "[[2331 3326]\n",
      " [1513 5621]]\n"
     ]
    }
   ],
   "source": [
    "field='statement'\n",
    "feature_reps=['binary','counts','tfidf']\n",
    "rf_clf = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "for feature_rep in feature_reps:\n",
    "        print(f'Model - {feature_rep} features with statement')\n",
    "        apply_kfold(rf_clf,train_val,field=field,feature_rep=feature_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Out of all the models fitted, we would take 2 best performing model. we would call them candidate models\n",
    "from the confusion matrix, we can see that logistic regression and SVM (with either binary or tfidf features) are better performing \n",
    "in terms of precision and recall (take a look into false positive and true negative counts which appeares\n",
    "to be low compared to rest of the models).\n",
    "\n",
    "Using k-fold cross validation, we see the performance of the models on the entire dataset. And, the model's aren't performing well. We can apply other features to improve the performance, and grid-search can also help us to find best parameters to improve the perfromance.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the best Model on entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "def extract_final_features(field,training_data,type):\n",
    "    \"\"\"Extract features using different methods\"\"\"\n",
    "    \n",
    "    logging.info(\"Extracting features and creating vocabulary...\")\n",
    "    \n",
    "    if \"binary\" in type:\n",
    "        \n",
    "        # BINARY FEATURE REPRESENTATION\n",
    "        cv= CountVectorizer(binary=True, max_df=0.95)\n",
    "        cv.fit_transform(training_data.values)\n",
    "        \n",
    "        train_feature_set=cv.transform(training_data.values)\n",
    "        \n",
    "        return train_feature_set,cv\n",
    "  \n",
    "    elif \"counts\" in type:\n",
    "        \n",
    "        # COUNT BASED FEATURE REPRESENTATION\n",
    "        cv= CountVectorizer(binary=False, max_df=0.95)\n",
    "        cv.fit_transform(training_data.values)\n",
    "        \n",
    "        train_feature_set=cv.transform(training_data.values)\n",
    "        \n",
    "        return train_feature_set,cv\n",
    "    \n",
    "    else:    \n",
    "        \n",
    "        # TF-IDF BASED FEATURE REPRESENTATION\n",
    "        tfidf_vectorizer=TfidfVectorizer(use_idf=True, max_df=0.95)\n",
    "        tfidf_vectorizer.fit_transform(training_data.values)\n",
    "        \n",
    "        train_feature_set=tfidf_vectorizer.transform(training_data.values)\n",
    "        \n",
    "        return train_feature_set,tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model(classifier, train_val, field=\"statement\",feature_rep=\"binary\"):\n",
    "    \"\"\"\n",
    "    Training the best classifier on entire dataset for the provided features.\n",
    "    \"\"\"\n",
    "    \n",
    "    logging.info(\"Starting model training...\")    \n",
    "\n",
    "    # features\n",
    "    train_x=train_val['statement']\n",
    "    \n",
    "    # GET LABELS\n",
    "    target=train_val['label'].values\n",
    "     \n",
    "    # GET FEATURES\n",
    "    features,feature_transformer=extract_final_features(field,train_x,type=feature_rep)\n",
    "\n",
    "    # INIT LOGISTIC REGRESSION CLASSIFIER\n",
    "    logging.info(\"Training a Final Model...\")\n",
    "#     scikit_log_reg = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "    model=classifier.fit(features,target)\n",
    "\n",
    "    logging.info(\"Done training.\")\n",
    "    \n",
    "    return model,feature_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model,X_test):\n",
    "    \n",
    "    # get predicted labels\n",
    "    pred = model.predict(X_test)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:26:16,433 : INFO : Starting model training...\n",
      "2020-11-20 16:26:16,435 : INFO : Extracting features and creating vocabulary...\n",
      "2020-11-20 16:26:16,859 : INFO : Training a Final Model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-20 16:26:17,140 : INFO : Done training.\n"
     ]
    }
   ],
   "source": [
    "field='statement'\n",
    "LogR_clf_final = LogisticRegression(verbose=1, solver='liblinear',random_state=0, C=5, penalty='l2',max_iter=1000)\n",
    "lr_final_model,transformer=train_final_model(LogR_clf_final,train_val,field=field,feature_rep='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check predictions on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.snopes.com/fact-check/alaska-town-60-days-without-sun/\n",
    "test_features=transformer.transform([\"The sun does not rise in Utqiagvik, Alaska, for more than 60 days during the winter.\"])\n",
    "ouput = get_predictions(lr_final_model,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ouput[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.politifact.com/factchecks/2020/nov/20/viral-image/no-passage-about-defeat-isnt-donald-trumps-art-dea/\n",
    "test_features=transformer.transform([\"Says Donald Trump’s book “The Art of the Deal” advises: “Never admit defeat. You win. If you don’t win, claim they cheated.”\"])\n",
    "ouput = get_predictions(lr_final_model,test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ouput[0] # this information is predicted as true, however, it should be false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_path=\"../models/lr_final_model.pkl\"\n",
    "transformer_path=\"../models/transformer.pkl\"\n",
    "\n",
    "# we need to save both the transformer -> to encode a document and the model itself to make predictions based on the weight vectors \n",
    "pickle.dump(lr_final_model,open(model_path, 'wb'))\n",
    "pickle.dump(transformer,open(transformer_path,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
